task:
  task_type: training
  project_name: celeba-faces-vaesd

callbacks:
  LearningRateMonitor:
    logging_interval: step

checkpoint:
  auto_insert_metric_name: false
  dirpath: /data/modeling/checkpoints
  filename: best_loss_{loss/val:.5f}_{step}
  monitor: gen_loss/val
  save_last: true
  save_top_k: 3
  verbose: true

dataloader:
  num_workers: 8
  batch_size: 16
  persistent_workers: True

data:
  dataset_name: FacesDataset
  common_kwargs:
    base_path: /data/datasets/celeba/images
    train_size: 0.9

trainer:
  accelerator: gpu
  log_every_n_steps: 50
  num_sanity_val_steps: 0
  precision: 16-mixed
  check_val_every_n_epoch: 1
  devices: [0]


model:
    model_name: VQVAE
    model_kwargs:
        im_channels: 3
        model_config:
            z_channels: 4
            codebook_size : 8192
            down_channels : [64, 128, 256, 256]
            mid_channels : [256, 256]
            down_sample : [True, True, True]
            attn_down : [False, False, False]
            norm_channels: 32
            num_heads: 4
            num_down_layers : 2
            num_mid_layers : 2
            num_up_layers : 2
    discriminator_kwargs:
        im_channels: 3
    model_lr: 0.00001
    model_betas: [0.5, 0.999]
    disc_lr: 0.00001
    disc_betas: [0.5, 0.999]
    disc_step_start: 15000
    codebook_weight: 1
    commitment_beta: 0.2
    disc_weight: 0.5
    perceptual_weight: 1
    viz_val_indices: [0, 10, 50, 100, 500, 1000]
    viz_train_indices: [0, 10, 50, 100, 500, 1000]
    viz_frequency: 1000
