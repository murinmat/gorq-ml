task:
  task_type: training
  project_name: latent-diffusion-train

callbacks:
  LearningRateMonitor:
    logging_interval: step

checkpoint:
  auto_insert_metric_name: false
  dirpath: /data/modeling/checkpoints/
  filename: best_loss_{loss/val:.5f}_{step}
  monitor: loss/val
  save_last: true
  save_top_k: 3
  verbose: true

dataloader:
  num_workers: 4
  batch_size: 16
  pin_memory: True
  persistent_workers: True

data:
  dataset_name: FacesDataset
  common_kwargs:
    base_path: /data/datasets/celeba/images
    train_size: 0.9

trainer:
  accelerator: gpu
  log_every_n_steps: 100
  num_sanity_val_steps: 2
  precision: 16-mixed
  check_val_every_n_epoch: 1
  devices: [0]


model:
    model_kwargs:
        im_channels: 6
        model_config:
          down_channels: [256, 512, 768, 1024]
          mid_channels: [1024, 768]
          down_sample: [True, True, True]
          attn_down : [True, True, True]
          time_emb_dim: 512
          norm_channels: 32
          num_heads: 16
          conv_out_channels : 128
          num_down_layers : 2
          num_mid_layers : 2
          num_up_layers : 2
    vae_model_name: VAELightning
    vae_ckpt_path: /data/modeling/checkpoints/vqvae-train/03-FaceGen-VQVAE;z=6;beta=0.5;dict-size=2048-continue/last.ckpt
    noise_scheduler_kwargs:
      num_timesteps: 1000
      beta_start: 0.0015
      beta_end: 0.0195
    model_lr: 0.000005
    latent_shape: [6, 64, 64]
    model_betas: [0.9, 0.999]
    viz_frequency: 2000
    num_inference_tsteps: 10
    viz_n_samples: 1
    viz_denoising_seed: 8
    input_img_resolution: 256
